# AiWorkflowActions Configuration File
# Create local.config.yml for custom configurations

# Global API Configuration
api:
  anthropic_api_key: <no_api_key>

# Global Model Configuration
models:
  node_generation: claude-sonnet-4-5-20250929       # Node generation model
  user_intent_inference: claude-sonnet-4-5-20250929 # User intent inference model
  judge: claude-sonnet-4-5-20250929                 # Judge evaluation model

evaluation:
  dataset:
    source_dsl_dir: resources/Awesome-Dify-Workflow/DSL
    total_samples: 90
    max_samples_per_file: 5
    excluded_node_types:
      - start
      - end
      - iteration-start
      - loop-start
      - loop-end
      - ""
  user_message_inference:
    prompt_template: src/evaluation/prompts/user_message_inference.txt
    temperature: 0.0
    max_tokens: 200
  judge:
    prompt_template: src/evaluation/prompts/llm_judge_eval.txt
    temperature: 0.0
    max_tokens: 7200
  retry:
    max_attempts: 3
    min_delay_seconds: 1.0
    max_delay_seconds: 5.0
  parallel:
    max_workers: 40                 # Thread pool max workers (1 = serial)
  output:
    judge_results_json: output/judge_results.json
    analysis_report: output/evaluation_report.md
